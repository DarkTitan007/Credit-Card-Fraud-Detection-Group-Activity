{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credt_Card_Fraud_Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdIS7i7jpWvr/z7Idn4RgB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarkTitan007/Credit-Card-Fraud-Detection-Group-Activity/blob/main/Credt_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t3E9tJqXsah"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.svm import OneClassSVM\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "LABELS = [\"Normal\", \"Fraud\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC3mbVoCmKgS"
      },
      "source": [
        "data = pd.read_csv('creditcard.csv',sep=',')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZNCNBKumM9y"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY8H4iYGmV7i"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5UdUNanmZdJ"
      },
      "source": [
        "count_classes = pd.value_counts(data['Class'], sort = True)\n",
        "\n",
        "count_classes.plot(kind = 'bar', rot=0)\n",
        "\n",
        "plt.title(\"Transaction Class Distribution\")\n",
        "\n",
        "plt.xticks(range(2), LABELS)\n",
        "\n",
        "plt.xlabel(\"Class\")\n",
        "\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npl02RNOmbz5"
      },
      "source": [
        "## Get the Fraud and the normal dataset \n",
        "\n",
        "fraud = data[data['Class']==1]\n",
        "\n",
        "normal = data[data['Class']==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J2x2tHsmfzJ"
      },
      "source": [
        "print(fraud.shape,normal.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4uyUZ_umlJa"
      },
      "source": [
        "## We need to analyze more amount of information from the transaction data\n",
        "#How different are the amount of money used in different transaction classes?\n",
        "fraud.Amount.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjuYstWLmnTK"
      },
      "source": [
        "normal.Amount.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w83coZ8FmpQC"
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "f.suptitle('Amount per transaction by class')\n",
        "bins = 50\n",
        "ax1.hist(fraud.Amount, bins = bins)\n",
        "ax1.set_title('Fraud')\n",
        "ax2.hist(normal.Amount, bins = bins)\n",
        "ax2.set_title('Normal')\n",
        "plt.xlabel('Amount ($)')\n",
        "plt.ylabel('Number of Transactions')\n",
        "plt.xlim((0, 20000))\n",
        "plt.yscale('log')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCeil4cmsCi"
      },
      "source": [
        "# We Will check Do fraudulent transactions occur more often during certain time frame ? Let us find out with a visual representation.\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "f.suptitle('Time of transaction vs Amount by class')\n",
        "ax1.scatter(Fraud.Time, Fraud.Amount)\n",
        "ax1.set_title('Fraud')\n",
        "ax2.scatter(Normal.Time, Normal.Amount)\n",
        "ax2.set_title('Normal')\n",
        "plt.xlabel('Time (in Seconds)')\n",
        "plt.ylabel('Amount')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKmLzpy1mujD"
      },
      "source": [
        "## Take some sample of the data\n",
        "\n",
        "data1= data.sample(frac = 0.1,random_state=1)\n",
        "\n",
        "data1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsiSaENamwzT"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAZ9eoQ7my9C"
      },
      "source": [
        "#Determine the number of fraud and valid transactions in the dataset\n",
        "\n",
        "Fraud = data1[data1['Class']==1]\n",
        "\n",
        "Valid = data1[data1['Class']==0]\n",
        "\n",
        "outlier_fraction = len(Fraud)/float(len(Valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkFnbhr_m1XS"
      },
      "source": [
        "print(outlier_fraction)\n",
        "\n",
        "print(\"Fraud Cases : {}\".format(len(Fraud)))\n",
        "\n",
        "print(\"Valid Cases : {}\".format(len(Valid)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiVUKyLgm4Hz"
      },
      "source": [
        "## Correlation\n",
        "import seaborn as sns\n",
        "#get correlations of each features in dataset\n",
        "corrmat = data1.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(20,20))\n",
        "#plot heat map\n",
        "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O94cPqHGm6gK"
      },
      "source": [
        "#Create independent and Dependent Features\n",
        "columns = data1.columns.tolist()\n",
        "# Filter the columns to remove data we do not want \n",
        "columns = [c for c in columns if c not in [\"Class\"]]\n",
        "# Store the variable we are predicting \n",
        "target = \"Class\"\n",
        "# Define a random state \n",
        "state = np.random.RandomState(42)\n",
        "X = data1[columns]\n",
        "Y = data1[target]\n",
        "X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n",
        "# Print the shapes of X & Y\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZXYA3UXm8oi"
      },
      "source": [
        "##Define the outlier detection methods\n",
        "\n",
        "classifiers = {\n",
        "    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X), \n",
        "                                       contamination=outlier_fraction,random_state=state, verbose=0),\n",
        "    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n",
        "                                              leaf_size=30, metric='minkowski',\n",
        "                                              p=2, metric_params=None, contamination=outlier_fraction),\n",
        "    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, \n",
        "                                         max_iter=-1, random_state=state)\n",
        "   \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3anb4BnGnAMi"
      },
      "source": [
        "type(classifiers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pel2CPIMnCGn"
      },
      "source": [
        "n_outliers = len(Fraud)\n",
        "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
        "    #Fit the data and tag outliers\n",
        "    if clf_name == \"Local Outlier Factor\":\n",
        "        y_pred = clf.fit_predict(X)\n",
        "        scores_prediction = clf.negative_outlier_factor_\n",
        "    elif clf_name == \"Support Vector Machine\":\n",
        "        clf.fit(X)\n",
        "        y_pred = clf.predict(X)\n",
        "    else:    \n",
        "        clf.fit(X)\n",
        "        scores_prediction = clf.decision_function(X)\n",
        "        y_pred = clf.predict(X)\n",
        "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
        "    y_pred[y_pred == 1] = 0\n",
        "    y_pred[y_pred == -1] = 1\n",
        "    n_errors = (y_pred != Y).sum()\n",
        "    # Run Classification Metrics\n",
        "    print(\"{}: {}\".format(clf_name,n_errors))\n",
        "    print(\"Accuracy Score :\")\n",
        "    print(accuracy_score(Y,y_pred))\n",
        "    print(\"Classification Report :\")\n",
        "    print(classification_report(Y,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro6Rbho7nEsa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}